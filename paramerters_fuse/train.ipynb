{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 微调最优单模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\86137\\.conda\\envs\\gym\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 1. 检查CUDA是否可用\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 2. 定义简单的多层感知机\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # 推理并计算准确度\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [300/600], Loss: 0.0547\n",
      "Epoch [1/20], Step [600/600], Loss: 0.1103\n",
      "Accuracy on the test set: 97.15%\n",
      "Epoch [1/20], Average Loss: 0.0603\n",
      "Epoch [2/20], Step [300/600], Loss: 0.1117\n",
      "Epoch [2/20], Step [600/600], Loss: 0.0235\n",
      "Accuracy on the test set: 97.52%\n",
      "Epoch [2/20], Average Loss: 0.0462\n",
      "Epoch [3/20], Step [300/600], Loss: 0.0121\n",
      "Epoch [3/20], Step [600/600], Loss: 0.0524\n",
      "Accuracy on the test set: 97.53%\n",
      "Epoch [3/20], Average Loss: 0.0397\n",
      "Epoch [4/20], Step [300/600], Loss: 0.0231\n",
      "Epoch [4/20], Step [600/600], Loss: 0.0274\n",
      "Accuracy on the test set: 97.76%\n",
      "Epoch [4/20], Average Loss: 0.0358\n",
      "Epoch [5/20], Step [300/600], Loss: 0.0212\n",
      "Epoch [5/20], Step [600/600], Loss: 0.0630\n",
      "Accuracy on the test set: 97.59%\n",
      "Epoch [5/20], Average Loss: 0.0308\n",
      "Epoch [6/20], Step [300/600], Loss: 0.0400\n",
      "Epoch [6/20], Step [600/600], Loss: 0.0313\n",
      "Accuracy on the test set: 97.49%\n",
      "Epoch [6/20], Average Loss: 0.0297\n",
      "Epoch [7/20], Step [300/600], Loss: 0.0038\n",
      "Epoch [7/20], Step [600/600], Loss: 0.0256\n",
      "Accuracy on the test set: 97.74%\n",
      "Epoch [7/20], Average Loss: 0.0257\n",
      "Epoch [8/20], Step [300/600], Loss: 0.0029\n",
      "Epoch [8/20], Step [600/600], Loss: 0.0361\n",
      "Accuracy on the test set: 97.60%\n",
      "Epoch [8/20], Average Loss: 0.0229\n",
      "Epoch [9/20], Step [300/600], Loss: 0.0281\n",
      "Epoch [9/20], Step [600/600], Loss: 0.0576\n",
      "Accuracy on the test set: 97.52%\n",
      "Epoch [9/20], Average Loss: 0.0237\n",
      "Epoch [10/20], Step [300/600], Loss: 0.0092\n",
      "Epoch [10/20], Step [600/600], Loss: 0.0125\n",
      "Accuracy on the test set: 97.40%\n",
      "Epoch [10/20], Average Loss: 0.0195\n",
      "Epoch [11/20], Step [300/600], Loss: 0.0119\n",
      "Epoch [11/20], Step [600/600], Loss: 0.0032\n",
      "Accuracy on the test set: 97.59%\n",
      "Epoch [11/20], Average Loss: 0.0191\n",
      "Epoch [12/20], Step [300/600], Loss: 0.0192\n",
      "Epoch [12/20], Step [600/600], Loss: 0.0169\n",
      "Accuracy on the test set: 97.69%\n",
      "Epoch [12/20], Average Loss: 0.0184\n",
      "Epoch [13/20], Step [300/600], Loss: 0.0003\n",
      "Epoch [13/20], Step [600/600], Loss: 0.0147\n",
      "Accuracy on the test set: 97.41%\n",
      "Epoch [13/20], Average Loss: 0.0158\n",
      "Epoch [14/20], Step [300/600], Loss: 0.0122\n",
      "Epoch [14/20], Step [600/600], Loss: 0.0120\n",
      "Accuracy on the test set: 97.49%\n",
      "Epoch [14/20], Average Loss: 0.0143\n",
      "Epoch [15/20], Step [300/600], Loss: 0.0204\n",
      "Epoch [15/20], Step [600/600], Loss: 0.0045\n",
      "Accuracy on the test set: 97.74%\n",
      "Epoch [15/20], Average Loss: 0.0142\n",
      "Epoch [16/20], Step [300/600], Loss: 0.0064\n",
      "Epoch [16/20], Step [600/600], Loss: 0.0117\n",
      "Accuracy on the test set: 97.38%\n",
      "Epoch [16/20], Average Loss: 0.0122\n",
      "Epoch [17/20], Step [300/600], Loss: 0.0025\n",
      "Epoch [17/20], Step [600/600], Loss: 0.0003\n",
      "Accuracy on the test set: 97.49%\n",
      "Epoch [17/20], Average Loss: 0.0113\n",
      "Epoch [18/20], Step [300/600], Loss: 0.0043\n",
      "Epoch [18/20], Step [600/600], Loss: 0.0154\n",
      "Accuracy on the test set: 97.74%\n",
      "Epoch [18/20], Average Loss: 0.0115\n",
      "Epoch [19/20], Step [300/600], Loss: 0.0075\n",
      "Epoch [19/20], Step [600/600], Loss: 0.0055\n",
      "Accuracy on the test set: 97.60%\n",
      "Epoch [19/20], Average Loss: 0.0112\n",
      "Epoch [20/20], Step [300/600], Loss: 0.0120\n",
      "Epoch [20/20], Step [600/600], Loss: 0.0010\n",
      "Accuracy on the test set: 97.42%\n",
      "Epoch [20/20], Average Loss: 0.0085\n",
      "Accuracy of the model on the 10000 test images: 97.42 %\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# 训练代码（不包括权重）\n",
    "# 加载MNIST数据集\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# 4. 定义损失函数和优化器\n",
    "model = SimpleMLP(784, 500, 10).to(device)\n",
    "state_dict1 = torch.load(\"1_96.13%.pth\")\n",
    "model.load_state_dict(state_dict1)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epoch_times = []\n",
    "\n",
    "# 5. 训练网络\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if (i+1) % 300 == 0:\n",
    "            print(\n",
    "                f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # 计算每个epoch的时间\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    epoch_times.append(elapsed_time)\n",
    "    accuracy = test_model(model, test_loader)\n",
    "\n",
    "    # 打印每轮epoch的average loss\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(\n",
    "        f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {average_loss:.4f}')\n",
    "\n",
    "# 6. 测试网络的性能\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(\n",
    "        f'Accuracy of the model on the 10000 test images: {100 * correct / total} %')\n",
    "\n",
    "# 7. 保存网络权重\n",
    "torch.save(model.state_dict(), f'./{seed}++_{100 * correct / total}%.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 微调融合单模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改网络，将可学习权重加进网络当中\n",
    "class CombinedMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, state_dicts):\n",
    "        super(CombinedMLP, self).__init__()\n",
    "        num_weights = len(state_dicts)\n",
    "\n",
    "        # 动态创建权重列表\n",
    "        self.weights = nn.ParameterList(\n",
    "            [nn.Parameter(torch.tensor(1.0)) for _ in range(num_weights)])\n",
    "\n",
    "        self.pretrained_weights = state_dicts\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # 使用softmax进行归一化\n",
    "        norm_weights = F.softmax(torch.stack([w for w in self.weights]), dim=0)\n",
    "\n",
    "        combined_weight1 = sum([norm_weights[i] * self.pretrained_weights[i]\n",
    "                               ['fc1.weight'] for i in range(len(self.weights))])\n",
    "        combined_bias1 = sum([norm_weights[i] * self.pretrained_weights[i]\n",
    "                             ['fc1.bias'] for i in range(len(self.weights))])\n",
    "        x = F.linear(x, combined_weight1, combined_bias1)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        combined_weight2 = sum([norm_weights[i] * self.pretrained_weights[i]\n",
    "                               ['fc2.weight'] for i in range(len(self.weights))])\n",
    "        combined_bias2 = sum([norm_weights[i] * self.pretrained_weights[i]\n",
    "                             ['fc2.bias'] for i in range(len(self.weights))])\n",
    "        x = F.linear(x, combined_weight2, combined_bias2)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 96.04%\n",
      "Accuracy on the test set: 96.04%\n",
      "Accuracy on the test set: 96.04%\n",
      "Accuracy on the test set: 96.04%\n",
      "Epoch [1/20], Step [300/600], Loss: 0.0726\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46264\\1085771235.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86137\\.conda\\envs\\gym\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86137\\.conda\\envs\\gym\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86137\\.conda\\envs\\gym\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86137\\.conda\\envs\\gym\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86137\\.conda\\envs\\gym\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86137\\.conda\\envs\\gym\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86137\\.conda\\envs\\gym\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \"\"\"\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86137\\.conda\\envs\\gym\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "state_dict1 = torch.load(\"1_96.13%.pth\")\n",
    "state_dict2 = torch.load(\"2_95.8%.pth\")\n",
    "state_dict3 = torch.load(\"3_95.94%.pth\")\n",
    "state_dict4 = torch.load(\"1_92.17%.pth\")\n",
    "state_dict5 = torch.load(\"2_92.05%.pth\")\n",
    "state_dict6 = torch.load(\"3_92.03%.pth\")\n",
    "\n",
    "# state_dicts = [state_dict1, state_dict2, state_dict3,\n",
    "#               state_dict4, state_dict5, state_dict6]\n",
    "state_dicts = [state_dict1,  state_dict3,\n",
    "               state_dict5, state_dict6]\n",
    "\n",
    "unnormalized_weights = [3.501100540161133,\n",
    "                        -0.06588193774223328, -1.0708355903625488, -1.384895920753479]\n",
    "\n",
    "weights = F.softmax(torch.tensor(unnormalized_weights), dim=0)\n",
    "\n",
    "model = SimpleMLP(28*28, 500, 10).to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.fc1.weight.data = sum(\n",
    "        [weights[i] * state_dicts[i]['fc1.weight'] for i in range(len(state_dicts))])\n",
    "    model.fc1.bias.data = sum(\n",
    "        [weights[i] * state_dicts[i]['fc1.bias'] for i in range(len(state_dicts))])\n",
    "    model.fc2.weight.data = sum(\n",
    "        [weights[i] * state_dicts[i]['fc2.weight'] for i in range(len(state_dicts))])\n",
    "    model.fc2.bias.data = sum(\n",
    "        [weights[i] * state_dicts[i]['fc2.bias'] for i in range(len(state_dicts))])\n",
    "\n",
    "accuracy = test_model(model, test_loader)\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n",
    "\n",
    "# 训练代码（不包括权重）\n",
    "# 加载MNIST数据集\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# 3. 训练SimpleMLP\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "accuracy = test_model(model, test_loader)\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n",
    "\n",
    "epoch_times = []\n",
    "\n",
    "# 5. 训练网络\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if (i+1) % 300 == 0:\n",
    "            print(\n",
    "                f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # 计算每个epoch的时间\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    epoch_times.append(elapsed_time)\n",
    "    accuracy = test_model(model, test_loader)\n",
    "\n",
    "    # 打印每轮epoch的average loss\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(\n",
    "        f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {average_loss:.4f}')\n",
    "\n",
    "# 6. 测试网络的性能\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(\n",
    "        f'Accuracy of the model on the 10000 test images: {100 * correct / total} %')\n",
    "\n",
    "# 7. 保存网络权重\n",
    "torch.save(model.state_dict(), f'./fuse1356_{100 * correct / total}%.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 96.22%\n",
      "Accuracy on the test set: 96.22%\n"
     ]
    }
   ],
   "source": [
    "state_dict1 = torch.load(\"1_96.13%.pth\")\n",
    "state_dict2 = torch.load(\"2_95.8%.pth\")\n",
    "state_dict3 = torch.load(\"3_95.94%.pth\")\n",
    "state_dict4 = torch.load(\"1_92.17%.pth\")\n",
    "state_dict5 = torch.load(\"2_92.05%.pth\")\n",
    "state_dict6 = torch.load(\"3_92.03%.pth\")\n",
    "\n",
    "state_dict = [state_dict1, state_dict2, state_dict3,\n",
    "              state_dict4, state_dict5, state_dict6]\n",
    "\n",
    "model = CombinedMLP(\n",
    "    28*28, 500, 10, state_dict).to(device)\n",
    "\n",
    "specific_weights = [3.999155044555664,\n",
    "                    0.18632793426513672, -1.046790599822998, 2.2161786556243896, -1.1982409954071045, -1.0864580869674683]\n",
    "\n",
    "for i, weight_value in enumerate(specific_weights):\n",
    "    model.weights[i].data = torch.tensor(weight_value).to(device)\n",
    "\n",
    "accuracy = test_model(model, test_loader)\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 38.76%\n"
     ]
    }
   ],
   "source": [
    "m_model = CombinedMLP(\n",
    "    28*28, 500, 10, state_dict).to(device)\n",
    "\n",
    "accuracy = test_model(m_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试伪标签预测错误或者正确样本的鲁棒性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练加权融合的模型\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: tensor([5.7115e-01, 1.1627e-13, 4.2885e-01, 1.1627e-13, 1.1627e-13, 1.5753e-06],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 0\n",
      "Accuracy on the test set: 80.48%\n",
      "count:0 - Sample:58355- Accuracy on the test set: 80.48%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:1 - Sample:33583- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 96.12%\n",
      "count:2 - Sample:17862- Accuracy on the test set: 96.12%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:3 - Sample:28517- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.14%\n",
      "count:4 - Sample:29135- Accuracy on the test set: 96.14%\n",
      "Accuracy on the test set: 96.15%\n",
      "count:5 - Sample:54842- Accuracy on the test set: 96.15%\n",
      "Accuracy on the test set: 73.63%\n",
      "count:6 - Sample:1176- Accuracy on the test set: 73.63%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:7 - Sample:20200- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.57%\n",
      "count:8 - Sample:46194- Accuracy on the test set: 95.57%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:9 - Sample:46903- Accuracy on the test set: 95.80%\n",
      "Weights: tensor([1.0000e+00, 2.4846e-12, 2.4845e-12, 2.4845e-12, 2.4846e-12, 2.4846e-12],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 0\n",
      "Accuracy on the test set: 96.13%\n",
      "count:10 - Sample:354- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 77.14%\n",
      "count:11 - Sample:35988- Accuracy on the test set: 77.14%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:12 - Sample:46045- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 79.65%\n",
      "count:13 - Sample:55605- Accuracy on the test set: 79.65%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:14 - Sample:24460- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 94.85%\n",
      "count:15 - Sample:36743- Accuracy on the test set: 94.85%\n",
      "Accuracy on the test set: 95.94%\n",
      "count:16 - Sample:42755- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:17 - Sample:59266- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:18 - Sample:14371- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.05%\n",
      "count:19 - Sample:24529- Accuracy on the test set: 95.05%\n",
      "Weights: tensor([8.6614e-13, 6.6280e-01, 3.3720e-01, 8.6614e-13, 8.6614e-13, 8.6614e-13],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 1\n",
      "Accuracy on the test set: 89.30%\n",
      "count:20 - Sample:36578- Accuracy on the test set: 89.30%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:21 - Sample:38448- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:22 - Sample:47201- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:23 - Sample:41961- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 88.51%\n",
      "count:24 - Sample:4587- Accuracy on the test set: 88.51%\n",
      "Accuracy on the test set: 95.81%\n",
      "count:25 - Sample:4672- Accuracy on the test set: 95.81%\n",
      "Accuracy on the test set: 96.00%\n",
      "count:26 - Sample:51475- Accuracy on the test set: 96.00%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:27 - Sample:54799- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:28 - Sample:24869- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.72%\n",
      "count:29 - Sample:25449- Accuracy on the test set: 95.72%\n",
      "Weights: tensor([1.7530e-13, 9.9783e-01, 2.1669e-03, 1.7530e-13, 9.3534e-07, 1.7530e-13],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 1\n",
      "Accuracy on the test set: 95.80%\n",
      "count:30 - Sample:46455- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:31 - Sample:2204- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.01%\n",
      "count:32 - Sample:41458- Accuracy on the test set: 96.01%\n",
      "Accuracy on the test set: 74.72%\n",
      "count:33 - Sample:39353- Accuracy on the test set: 74.72%\n",
      "Accuracy on the test set: 96.15%\n",
      "count:34 - Sample:3770- Accuracy on the test set: 96.15%\n",
      "Accuracy on the test set: 96.00%\n",
      "count:35 - Sample:21181- Accuracy on the test set: 96.00%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:36 - Sample:28809- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 88.37%\n",
      "count:37 - Sample:14155- Accuracy on the test set: 88.37%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:38 - Sample:58717- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 95.77%\n",
      "count:39 - Sample:6313- Accuracy on the test set: 95.77%\n",
      "Weights: tensor([9.9998e-01, 9.4018e-13, 9.4018e-13, 9.4018e-13, 9.4018e-13, 2.0449e-05],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 0\n",
      "Accuracy on the test set: 96.13%\n",
      "count:40 - Sample:21698- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.94%\n",
      "count:41 - Sample:53654- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:42 - Sample:40319- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 94.77%\n",
      "count:43 - Sample:2533- Accuracy on the test set: 94.77%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:44 - Sample:29989- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.09%\n",
      "count:45 - Sample:46564- Accuracy on the test set: 96.09%\n",
      "Accuracy on the test set: 96.14%\n",
      "count:46 - Sample:25495- Accuracy on the test set: 96.14%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:47 - Sample:41838- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:48 - Sample:17990- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:49 - Sample:53517- Accuracy on the test set: 96.13%\n",
      "Weights: tensor([2.6445e-06, 5.1371e-13, 1.0000e+00, 5.1373e-13, 5.1373e-13, 5.1373e-13],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 2\n",
      "Accuracy on the test set: 95.94%\n",
      "count:50 - Sample:10905- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:51 - Sample:59776- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:52 - Sample:3821- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 95.81%\n",
      "count:53 - Sample:1156- Accuracy on the test set: 95.81%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:54 - Sample:3738- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 74.77%\n",
      "count:55 - Sample:45458- Accuracy on the test set: 74.77%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:56 - Sample:32037- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:57 - Sample:9057- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:58 - Sample:46295- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:59 - Sample:24130- Accuracy on the test set: 96.13%\n",
      "Weights: tensor([1.5403e-12, 9.9957e-01, 4.2851e-04, 1.5403e-12, 1.5403e-12, 1.5403e-12],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 1\n",
      "Accuracy on the test set: 95.80%\n",
      "count:60 - Sample:21055- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 94.74%\n",
      "count:61 - Sample:9787- Accuracy on the test set: 94.74%\n",
      "Accuracy on the test set: 94.76%\n",
      "count:62 - Sample:33879- Accuracy on the test set: 94.76%\n",
      "Accuracy on the test set: 95.93%\n",
      "count:63 - Sample:8523- Accuracy on the test set: 95.93%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:64 - Sample:13385- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:65 - Sample:21372- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 71.84%\n",
      "count:66 - Sample:590- Accuracy on the test set: 71.84%\n",
      "Accuracy on the test set: 95.94%\n",
      "count:67 - Sample:28515- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 95.39%\n",
      "count:68 - Sample:43233- Accuracy on the test set: 95.39%\n",
      "Accuracy on the test set: 93.19%\n",
      "count:69 - Sample:58992- Accuracy on the test set: 93.19%\n",
      "Weights: tensor([1.0000e+00, 2.4845e-12, 2.4845e-12, 2.4845e-12, 2.4845e-12, 2.4844e-12],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 0\n",
      "Accuracy on the test set: 96.13%\n",
      "count:70 - Sample:26936- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 93.09%\n",
      "count:71 - Sample:51305- Accuracy on the test set: 93.09%\n",
      "Accuracy on the test set: 95.47%\n",
      "count:72 - Sample:37734- Accuracy on the test set: 95.47%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:73 - Sample:56141- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 93.91%\n",
      "count:74 - Sample:23365- Accuracy on the test set: 93.91%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:75 - Sample:6500- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 95.94%\n",
      "count:76 - Sample:12963- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 95.99%\n",
      "count:77 - Sample:3421- Accuracy on the test set: 95.99%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:78 - Sample:29207- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:79 - Sample:47477- Accuracy on the test set: 95.80%\n",
      "Weights: tensor([2.2739e-13, 1.0000e+00, 4.8267e-06, 2.2739e-13, 2.2739e-13, 2.2739e-13],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 1\n",
      "Accuracy on the test set: 95.80%\n",
      "count:80 - Sample:51261- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 71.21%\n",
      "count:81 - Sample:45719- Accuracy on the test set: 71.21%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:82 - Sample:31985- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:83 - Sample:16252- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 95.94%\n",
      "count:84 - Sample:20957- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:85 - Sample:21395- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:86 - Sample:36681- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.10%\n",
      "count:87 - Sample:26776- Accuracy on the test set: 96.10%\n",
      "Accuracy on the test set: 96.10%\n",
      "count:88 - Sample:52367- Accuracy on the test set: 96.10%\n",
      "Accuracy on the test set: 76.14%\n",
      "count:89 - Sample:17688- Accuracy on the test set: 76.14%\n",
      "Weights: tensor([6.6008e-05, 1.8759e-13, 9.9993e-01, 1.8759e-13, 1.8759e-13, 1.8759e-13],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 2\n",
      "Accuracy on the test set: 95.94%\n",
      "count:90 - Sample:3354- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:91 - Sample:3701- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 93.20%\n",
      "count:92 - Sample:34834- Accuracy on the test set: 93.20%\n",
      "Accuracy on the test set: 87.63%\n",
      "count:93 - Sample:20195- Accuracy on the test set: 87.63%\n",
      "Accuracy on the test set: 96.11%\n",
      "count:94 - Sample:5296- Accuracy on the test set: 96.11%\n",
      "Accuracy on the test set: 96.12%\n",
      "count:95 - Sample:6506- Accuracy on the test set: 96.12%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:96 - Sample:47481- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 94.52%\n",
      "count:97 - Sample:5549- Accuracy on the test set: 94.52%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:98 - Sample:54748- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 70.91%\n",
      "count:99 - Sample:6049- Accuracy on the test set: 70.91%\n",
      "Weights: tensor([7.9068e-01, 1.4158e-13, 2.0932e-01, 1.4158e-13, 1.4158e-13, 1.7315e-06],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 0\n",
      "Accuracy on the test set: 94.96%\n",
      "count:100 - Sample:58286- Accuracy on the test set: 94.96%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:101 - Sample:28580- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 95.94%\n",
      "count:102 - Sample:31885- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 94.50%\n",
      "count:103 - Sample:40448- Accuracy on the test set: 94.50%\n",
      "Accuracy on the test set: 95.77%\n",
      "count:104 - Sample:3101- Accuracy on the test set: 95.77%\n",
      "Accuracy on the test set: 96.14%\n",
      "count:105 - Sample:3630- Accuracy on the test set: 96.14%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:106 - Sample:13452- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.15%\n",
      "count:107 - Sample:46738- Accuracy on the test set: 96.15%\n",
      "Accuracy on the test set: 96.11%\n",
      "count:108 - Sample:39551- Accuracy on the test set: 96.11%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:109 - Sample:13780- Accuracy on the test set: 95.80%\n",
      "Weights: tensor([1.0000e+00, 2.3881e-13, 1.9750e-06, 2.3881e-13, 2.3881e-13, 2.3881e-13],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 0\n",
      "Accuracy on the test set: 96.13%\n",
      "count:110 - Sample:963- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 94.20%\n",
      "count:111 - Sample:22511- Accuracy on the test set: 94.20%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:112 - Sample:27237- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:113 - Sample:2140- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 90.54%\n",
      "count:114 - Sample:22091- Accuracy on the test set: 90.54%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:115 - Sample:7684- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:116 - Sample:15151- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:117 - Sample:412- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:118 - Sample:5705- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:119 - Sample:34842- Accuracy on the test set: 96.13%\n",
      "Weights: tensor([1.3062e-06, 7.3479e-01, 2.6521e-01, 1.6819e-13, 1.6819e-13, 1.3746e-06],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 1\n",
      "Accuracy on the test set: 92.57%\n",
      "count:120 - Sample:39002- Accuracy on the test set: 92.57%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:121 - Sample:10927- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.46%\n",
      "count:122 - Sample:13402- Accuracy on the test set: 95.46%\n",
      "Accuracy on the test set: 86.70%\n",
      "count:123 - Sample:35566- Accuracy on the test set: 86.70%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:124 - Sample:29392- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 71.60%\n",
      "count:125 - Sample:10454- Accuracy on the test set: 71.60%\n",
      "Accuracy on the test set: 95.94%\n",
      "count:126 - Sample:15918- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 95.71%\n",
      "count:127 - Sample:14097- Accuracy on the test set: 95.71%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:128 - Sample:46549- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 75.11%\n",
      "count:129 - Sample:40600- Accuracy on the test set: 75.11%\n",
      "Weights: tensor([2.4845e-12, 2.4845e-12, 1.0000e+00, 2.4845e-12, 2.4845e-12, 2.4845e-12],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 2\n",
      "Accuracy on the test set: 95.94%\n",
      "count:130 - Sample:10103- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 95.94%\n",
      "count:131 - Sample:57070- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 79.92%\n",
      "count:132 - Sample:14401- Accuracy on the test set: 79.92%\n",
      "Accuracy on the test set: 96.01%\n",
      "count:133 - Sample:24206- Accuracy on the test set: 96.01%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:134 - Sample:5609- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 74.77%\n",
      "count:135 - Sample:11568- Accuracy on the test set: 74.77%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:136 - Sample:2715- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:137 - Sample:36727- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:138 - Sample:55983- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:139 - Sample:59771- Accuracy on the test set: 95.80%\n",
      "Weights: tensor([2.4845e-12, 1.0000e+00, 2.4845e-12, 2.4853e-12, 2.4846e-12, 2.4845e-12],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 1\n",
      "Accuracy on the test set: 95.80%\n",
      "count:140 - Sample:36193- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:141 - Sample:33721- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 86.86%\n",
      "count:142 - Sample:9379- Accuracy on the test set: 86.86%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:143 - Sample:44938- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:144 - Sample:3082- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:145 - Sample:57697- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 70.85%\n",
      "count:146 - Sample:58504- Accuracy on the test set: 70.85%\n",
      "Accuracy on the test set: 95.29%\n",
      "count:147 - Sample:38957- Accuracy on the test set: 95.29%\n",
      "Accuracy on the test set: 96.10%\n",
      "count:148 - Sample:39304- Accuracy on the test set: 96.10%\n",
      "Accuracy on the test set: 96.12%\n",
      "count:149 - Sample:19685- Accuracy on the test set: 96.12%\n",
      "Weights: tensor([9.9639e-01, 1.7498e-13, 3.6106e-03, 1.7498e-13, 1.7498e-13, 1.4028e-06],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 0\n",
      "Accuracy on the test set: 96.12%\n",
      "count:150 - Sample:53233- Accuracy on the test set: 96.12%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:151 - Sample:31931- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 92.42%\n",
      "count:152 - Sample:6643- Accuracy on the test set: 92.42%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:153 - Sample:52946- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:154 - Sample:51279- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.99%\n",
      "count:155 - Sample:59422- Accuracy on the test set: 95.99%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:156 - Sample:35713- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:157 - Sample:19076- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.96%\n",
      "count:158 - Sample:25419- Accuracy on the test set: 95.96%\n",
      "Accuracy on the test set: 95.99%\n",
      "count:159 - Sample:819- Accuracy on the test set: 95.99%\n",
      "Weights: tensor([9.9216e-01, 7.8372e-03, 6.4256e-13, 6.4257e-13, 6.4256e-13, 6.4256e-13],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 0\n",
      "Accuracy on the test set: 96.10%\n",
      "count:160 - Sample:7751- Accuracy on the test set: 96.10%\n",
      "Accuracy on the test set: 95.94%\n",
      "count:161 - Sample:47816- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 74.58%\n",
      "count:162 - Sample:26759- Accuracy on the test set: 74.58%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:163 - Sample:2073- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 92.22%\n",
      "count:164 - Sample:33523- Accuracy on the test set: 92.22%\n",
      "Accuracy on the test set: 89.89%\n",
      "count:165 - Sample:51282- Accuracy on the test set: 89.89%\n",
      "Accuracy on the test set: 96.15%\n",
      "count:166 - Sample:48652- Accuracy on the test set: 96.15%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:167 - Sample:19447- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 80.09%\n",
      "count:168 - Sample:53260- Accuracy on the test set: 80.09%\n",
      "Accuracy on the test set: 95.37%\n",
      "count:169 - Sample:48809- Accuracy on the test set: 95.37%\n",
      "Weights: tensor([8.3977e-01, 1.6023e-01, 9.5925e-13, 9.5925e-13, 9.5925e-13, 9.5925e-13],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 0\n",
      "Accuracy on the test set: 95.16%\n",
      "count:170 - Sample:2350- Accuracy on the test set: 95.16%\n",
      "Accuracy on the test set: 96.15%\n",
      "count:171 - Sample:20361- Accuracy on the test set: 96.15%\n",
      "Accuracy on the test set: 96.12%\n",
      "count:172 - Sample:36891- Accuracy on the test set: 96.12%\n",
      "Accuracy on the test set: 92.28%\n",
      "count:173 - Sample:4497- Accuracy on the test set: 92.28%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:174 - Sample:45026- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:175 - Sample:8955- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 71.01%\n",
      "count:176 - Sample:36005- Accuracy on the test set: 71.01%\n",
      "Accuracy on the test set: 84.73%\n",
      "count:177 - Sample:34931- Accuracy on the test set: 84.73%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:178 - Sample:19467- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.01%\n",
      "count:179 - Sample:16187- Accuracy on the test set: 96.01%\n",
      "Weights: tensor([9.7345e-01, 2.6548e-02, 1.7591e-13, 4.8104e-06, 1.7591e-13, 1.7591e-13],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 0\n",
      "Accuracy on the test set: 96.13%\n",
      "count:180 - Sample:38632- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:181 - Sample:1616- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:182 - Sample:57580- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:183 - Sample:58666- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.80%\n",
      "count:184 - Sample:38186- Accuracy on the test set: 95.80%\n",
      "Accuracy on the test set: 70.93%\n",
      "count:185 - Sample:12187- Accuracy on the test set: 70.93%\n",
      "Accuracy on the test set: 96.12%\n",
      "count:186 - Sample:3739- Accuracy on the test set: 96.12%\n",
      "Accuracy on the test set: 96.11%\n",
      "count:187 - Sample:4621- Accuracy on the test set: 96.11%\n",
      "Accuracy on the test set: 81.93%\n",
      "count:188 - Sample:25481- Accuracy on the test set: 81.93%\n",
      "Accuracy on the test set: 96.14%\n",
      "count:189 - Sample:43515- Accuracy on the test set: 96.14%\n",
      "Weights: tensor([4.5381e-13, 6.4006e-06, 9.9999e-01, 3.3595e-06, 4.5382e-13, 4.5382e-13],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Index of the maximum weight: 2\n",
      "Accuracy on the test set: 95.94%\n",
      "count:190 - Sample:27353- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 95.97%\n",
      "count:191 - Sample:1889- Accuracy on the test set: 95.97%\n",
      "Accuracy on the test set: 96.06%\n",
      "count:192 - Sample:59763- Accuracy on the test set: 96.06%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:193 - Sample:55620- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:194 - Sample:6133- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 70.90%\n",
      "count:195 - Sample:1628- Accuracy on the test set: 70.90%\n",
      "Accuracy on the test set: 96.13%\n",
      "count:196 - Sample:14990- Accuracy on the test set: 96.13%\n",
      "Accuracy on the test set: 95.94%\n",
      "count:197 - Sample:15995- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 95.94%\n",
      "count:198 - Sample:31882- Accuracy on the test set: 95.94%\n",
      "Accuracy on the test set: 94.82%\n",
      "count:199 - Sample:31225- Accuracy on the test set: 94.82%\n",
      "Best accuracy: 96.15%.\n",
      "Worst accuracy: 70.85%.\n",
      "Average accuracy: 93.22%.\n",
      "Variance of accuracy: 44.05%^2.\n",
      "Count of choosing the best model: 112\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "state_dict1 = torch.load(\"1_96.13%.pth\")\n",
    "state_dict2 = torch.load(\"2_95.8%.pth\")\n",
    "state_dict3 = torch.load(\"3_95.94%.pth\")\n",
    "state_dict4 = torch.load(\"1_92.17%.pth\")\n",
    "state_dict5 = torch.load(\"2_92.05%.pth\")\n",
    "state_dict6 = torch.load(\"3_92.03%.pth\")\n",
    "\n",
    "state_dict = [state_dict1, state_dict2, state_dict3,\n",
    "              state_dict4, state_dict5, state_dict6]\n",
    "\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # 推理并计算准确度\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# train_times = []  # 用于记录每次训练的时间\n",
    "\n",
    "\n",
    "# 从数据集中随机选择200个样本\n",
    "indices = torch.randperm(len(train_dataset))\n",
    "\n",
    "accuracies = []  # 用于记录每次训练后的精度\n",
    "\n",
    "STEPS_PER_SAMPLE = 2  # 设置每个样本的训练步骤数\n",
    "\n",
    "count = 0 # 记录处理的样本数\n",
    "best_accuracy = 0.0\n",
    "worst_accuracy = 100.0\n",
    "\n",
    "max_index_count = 0  # 记录选择到最优模型的次数\n",
    "\n",
    "\n",
    "for index in indices:\n",
    "    # 对于每个样本，重置模型\n",
    "    model = CombinedMLP(28*28, 500, 10, state_dict).to(device)\n",
    "    optimizer = optim.Adam(model.weights.parameters(), lr=8)\n",
    "\n",
    "    # 选择单个样本\n",
    "    single_data = torch.utils.data.Subset(train_dataset, [index])\n",
    "    single_loader = torch.utils.data.DataLoader(\n",
    "        dataset=single_data, batch_size=1, shuffle=False)\n",
    "\n",
    "    inputs, labels = next(iter(single_loader))\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, pseudo_labels = torch.max(outputs.data, 1)\n",
    "\n",
    "    # # 如果伪标签与实际标签匹配，则继续下一个样本\n",
    "    if (pseudo_labels != labels).item():\n",
    "        continue\n",
    "\n",
    "    for _ in range(STEPS_PER_SAMPLE):\n",
    "        # for inputs, labels in single_loader:\n",
    "        #     inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # outputs = model(inputs)\n",
    "        # _, pseudo_labels = torch.max(outputs.data, 1)\n",
    "        # print(pseudo_labels==labels)\n",
    "\n",
    "        loss = criterion(outputs, pseudo_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, pseudo_labels = torch.max(outputs.data, 1)\n",
    "\n",
    "    norm_weights = F.softmax(torch.stack([w for w in model.weights]), dim=0)\n",
    "    max_index = torch.argmax(norm_weights).item()  # 获取最大值的索引\n",
    "    if max_index == 0:\n",
    "        max_index_count += 1\n",
    "\n",
    "    # 每10下打印一次weights，以免没有更新\n",
    "    if count % 10 == 0:\n",
    "        print(\"Weights:\", norm_weights)\n",
    "        print(\"Index of the maximum weight:\", max_index)\n",
    "\n",
    "\n",
    "    # end_time = time.time()  # 结束计时\n",
    "    # train_times.append(end_time - start_time)  # 计算并记录训练时间\n",
    "\n",
    "    # 评估模型的性能\n",
    "    accuracy = test_model(model, test_loader)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"count:{count} - Sample:{index}- Accuracy on the test set: {accuracy:.2f}%\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "    if accuracy < worst_accuracy:\n",
    "        worst_accuracy = accuracy\n",
    "\n",
    "    count += 1\n",
    "    if count >= 200:\n",
    "        break\n",
    "\n",
    "# 计算精度的mean和var\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "var_accuracy = np.var(accuracies)\n",
    "\n",
    "print(f\"Best accuracy: {best_accuracy:.2f}%.\")\n",
    "print(f\"Worst accuracy: {worst_accuracy:.2f}%.\")\n",
    "print(f\"Average accuracy: {mean_accuracy:.2f}%.\")\n",
    "print(f\"Variance of accuracy: {var_accuracy:.2f}%^2.\")\n",
    "print(f\"Count of choosing the best model: {max_index_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
