{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# class SimpleMLP(nn.Module):\n",
    "\n",
    "#     def __init__(self, input_size, hidden_size, num_classes, models=None):\n",
    "#         super(SimpleMLP, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "#         self.models = models\n",
    "\n",
    "#     def forward(self, x, weights=None):\n",
    "#         if weights is not None and self.models is not None:\n",
    "#             # If weights are provided and models are set for fusion\n",
    "#             self._fuse_weights(weights)\n",
    "\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "#     def _fuse_weights(self, weights):\n",
    "#         alpha, beta, gamma = weights\n",
    "#         for (name, param), model1_param, model2_param, model3_param in zip(self.named_parameters(),\n",
    "#                                                                            self.models[0].named_parameters(),\n",
    "#                                                                            self.models[1].named_parameters(),\n",
    "#                                                                            self.models[2].named_parameters()):\n",
    "#             if name.endswith('weight') or name.endswith('bias'):\n",
    "#                 param.data = (alpha * model1_param[1].data +\n",
    "#                               beta * model2_param[1].data +\n",
    "#                               gamma * model3_param[1].data)\n",
    "\n",
    "\n",
    "\n",
    "    # def forward_with_fusion(self, x, model1, model2, model3, alpha, beta, gamma):\n",
    "    #     for param_fusion, param1, param2, param3 in zip(self.parameters(), model1.parameters(), model2.parameters(), model3.parameters()):\n",
    "    #         # print(\"param_fusion.data:\", param_fusion.data)\n",
    "    #         param_fusion.data = (alpha * param1.data + beta * \\\n",
    "    #             param2.data + gamma * param3.data) / (alpha + beta + gamma)\n",
    "\n",
    "    #     return self.forward(x)\n",
    "\n",
    "# 1. 检查CUDA是否可用\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 2. 定义简单的多层感知机\n",
    "\n",
    "seed = 3\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 1.3662\n",
      "Epoch [1/5], Step [200/600], Loss: 0.9781\n",
      "Epoch [1/5], Step [300/600], Loss: 0.5905\n",
      "Epoch [1/5], Step [400/600], Loss: 0.4220\n",
      "Epoch [1/5], Step [500/600], Loss: 0.4833\n",
      "Epoch [1/5], Step [600/600], Loss: 0.4650\n",
      "Epoch [2/5], Step [100/600], Loss: 0.5053\n",
      "Epoch [2/5], Step [200/600], Loss: 0.4735\n",
      "Epoch [2/5], Step [300/600], Loss: 0.4230\n",
      "Epoch [2/5], Step [400/600], Loss: 0.4392\n",
      "Epoch [2/5], Step [500/600], Loss: 0.3488\n",
      "Epoch [2/5], Step [600/600], Loss: 0.2717\n",
      "Epoch [3/5], Step [100/600], Loss: 0.2979\n",
      "Epoch [3/5], Step [200/600], Loss: 0.3149\n",
      "Epoch [3/5], Step [300/600], Loss: 0.2674\n",
      "Epoch [3/5], Step [400/600], Loss: 0.2574\n",
      "Epoch [3/5], Step [500/600], Loss: 0.4853\n",
      "Epoch [3/5], Step [600/600], Loss: 0.3642\n",
      "Epoch [4/5], Step [100/600], Loss: 0.4420\n",
      "Epoch [4/5], Step [200/600], Loss: 0.3443\n",
      "Epoch [4/5], Step [300/600], Loss: 0.5042\n",
      "Epoch [4/5], Step [400/600], Loss: 0.1626\n",
      "Epoch [4/5], Step [500/600], Loss: 0.2240\n",
      "Epoch [4/5], Step [600/600], Loss: 0.3058\n",
      "Epoch [5/5], Step [100/600], Loss: 0.2472\n",
      "Epoch [5/5], Step [200/600], Loss: 0.2570\n",
      "Epoch [5/5], Step [300/600], Loss: 0.3016\n",
      "Epoch [5/5], Step [400/600], Loss: 0.3657\n",
      "Epoch [5/5], Step [500/600], Loss: 0.3590\n",
      "Epoch [5/5], Step [600/600], Loss: 0.3113\n",
      "Accuracy of the model on the 10000 test images: 92.03 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. 加载MNIST数据集\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# 4. 定义损失函数和优化器\n",
    "model = SimpleMLP(784, 500, 10).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 5. 训练网络\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(\n",
    "                f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 6. 测试网络的性能\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(\n",
    "        f'Accuracy of the model on the 10000 test images: {100 * correct / total} %')\n",
    "\n",
    "# 7. 保存网络权重\n",
    "torch.save(model.state_dict(), f'./{seed}_{100 * correct / total}%.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0154, -0.0187, -0.0099,  ...,  0.0038, -0.0070, -0.0005],\n",
      "        [-0.0266, -0.0217, -0.0302,  ..., -0.0022,  0.0020, -0.0159],\n",
      "        [ 0.0283, -0.0093, -0.0339,  ..., -0.0139,  0.0058, -0.0334],\n",
      "        ...,\n",
      "        [ 0.0301, -0.0203, -0.0329,  ...,  0.0113, -0.0294,  0.0163],\n",
      "        [ 0.0156, -0.0219, -0.0285,  ..., -0.0188, -0.0348,  0.0248],\n",
      "        [ 0.0257, -0.0343, -0.0230,  ...,  0.0342,  0.0068,  0.0211]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model1 = SimpleMLP(784, 500, 10).to(device)\n",
    "model2 = SimpleMLP(784, 500, 10).to(device)\n",
    "model3 = SimpleMLP(784, 500, 10).to(device)\n",
    "model1.load_state_dict(torch.load(\"1_92.17%.pth\"))\n",
    "model2.load_state_dict(torch.load(\"2_92.05%.pth\"))\n",
    "model3.load_state_dict(torch.load(\"3_92.03%.pth\"))\n",
    "print(model1.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 33\n",
      "最初的alpha: tensor([0.1756], device='cuda:0', requires_grad=True) 最初的beta: tensor([-0.6090], device='cuda:0', requires_grad=True) 最初的gamma: tensor([0.1939], device='cuda:0', requires_grad=True)\n",
      "None None None\n",
      "tensor([-0.0001], device='cuda:0') tensor([0.0023], device='cuda:0') tensor([-0.0022], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model1 = SimpleMLP(784, 500, 10).to(device)\n",
    "model2 = SimpleMLP(784, 500, 10).to(device)\n",
    "model3 = SimpleMLP(784, 500, 10).to(device)\n",
    "model1.load_state_dict(torch.load(\"1_92.17%.pth\"))\n",
    "model2.load_state_dict(torch.load(\"2_92.05%.pth\"))\n",
    "model3.load_state_dict(torch.load(\"3_92.03%.pth\"))\n",
    "\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # 推理并计算准确度\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def weighted_sum_parameters(fusion_model, models, weights):\n",
    "    # 使用zip将每个模型的参数和权重组合起来\n",
    "    for params in zip(fusion_model.parameters(), *[model.parameters() for model in models]):\n",
    "        weighted_param = sum(w * p for w, p in zip(weights, params))\n",
    "        with torch.no_grad():  # 使用no_grad()来避免记录此操作\n",
    "            params[0].copy_(weighted_param)\n",
    "\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "for seed in range(33, 34):\n",
    "    print(\"SEED:\",seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    alpha = torch.randn(1, device=device, requires_grad=True)\n",
    "    beta = torch.randn(1, device=device, requires_grad=True)\n",
    "    gamma = torch.randn(1, device=device, requires_grad=True)\n",
    "\n",
    "    weights = torch.softmax(torch.stack([alpha, beta, gamma]), dim=0)\n",
    "    models = [model1, model2, model3]\n",
    "    print('最初的alpha:', alpha, '最初的beta:', beta, '最初的gamma:', gamma)\n",
    "    print(alpha.grad, beta.grad, gamma.grad)\n",
    "\n",
    "\n",
    "    fusion_model = SimpleMLP(784, 500, 10).to(device)\n",
    "    weighted_sum_parameters(fusion_model, models, weights)\n",
    "\n",
    "    # 4. 训练加权融合的模型\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=True, transform=transform, download=True)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=False, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam([alpha, beta, gamma], lr=0.005)\n",
    "\n",
    "    num_epochs = 5\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # 使用softmax归一化权重\n",
    "\n",
    "            # 在每次迭代之前，使用alpha和beta的当前值更新fusion_model的参数\n",
    "            # weighted_sum_parameters(fusion_model, models, weights)\n",
    "\n",
    "            weights = torch.softmax(torch.stack([alpha, beta, gamma]), dim=0)\n",
    "\n",
    "            # 计算每个模型的输出\n",
    "            outputs1 = model1(inputs)\n",
    "            outputs2 = model2(inputs)\n",
    "            outputs3 = model3(inputs)\n",
    "\n",
    "            # 计算加权和的输出\n",
    "            outputs = weights[0] * outputs1 + weights[1] * \\\n",
    "                outputs2 + weights[2] * outputs3\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # outputs = fusion_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            print(alpha.grad, beta.grad, gamma.grad)\n",
    "            # print(weights[0].grad, weights[1].grad, weights[2].grad)\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(\n",
    "                    f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        print(\"alpha:\", weights[0], \"beta:\",\n",
    "              weights[1], \"gamma:\", weights[2])\n",
    "        # print(\"alpha:\", alpha, \"beta:\",\n",
    "        #       beta, \"gamma:\", gamma)\n",
    "\n",
    "\n",
    "    accuracy = test_model(fusion_model, test_loader)\n",
    "    print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_alpha = weights[0]\n",
    "        best_beta = weights[1]\n",
    "        best_gamma = weights[2]\n",
    "        best_seed = seed\n",
    "\n",
    "# 保存alpha和beta的值\n",
    "print(best_alpha.item(), best_beta.item(), best_gamma.item(), best_seed)\n",
    "torch.save({\"alpha\": best_alpha.item(), \"beta\": best_beta.item(),\n",
    "           \"gamma\": best_gamma.item()}, \"weights.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"alpha\": best_alpha.item(),\n",
    "           \"beta\": best_beta.item()}, \"weights.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.09341243654489517 beta: 0.8814216256141663\n"
     ]
    }
   ],
   "source": [
    "loaded_weights = torch.load(\"weights.pth\")\n",
    "loaded_alpha = loaded_weights[\"alpha\"]\n",
    "loaded_beta = loaded_weights[\"beta\"]\n",
    "print(\"alpha:\",loaded_alpha, \"beta:\",loaded_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.8721233606338501 beta: 1.0146440267562866 gamma: 0.8551493287086487\n",
      "Accuracy on the test set: 92.10%\n"
     ]
    }
   ],
   "source": [
    "seed = best_seed\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "model1 = SimpleMLP(784, 500, 10).to(device)\n",
    "model2 = SimpleMLP(784, 500, 10).to(device)\n",
    "model3 = SimpleMLP(784, 500, 10).to(device)\n",
    "model1.load_state_dict(torch.load(\"1_92.17%.pth\"))\n",
    "model2.load_state_dict(torch.load(\"2_92.05%.pth\"))\n",
    "model3.load_state_dict(torch.load(\"3_92.03%.pth\"))\n",
    "loaded_weights = torch.load(\"weights.pth\")\n",
    "loaded_alpha = loaded_weights[\"alpha\"]\n",
    "loaded_beta = loaded_weights[\"beta\"]\n",
    "loaded_gamma = loaded_weights[\"gamma\"]\n",
    "# loaded_alpha = torch.tensor([1.0], requires_grad=True).to(device)\n",
    "# loaded_beta = torch.tensor([0.0], requires_grad=True).to(device)\n",
    "print(\"alpha:\", loaded_alpha, \"beta:\", loaded_beta, \"gamma:\", loaded_gamma)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "\n",
    "# 加载权重\n",
    "# model = SimpleMLP(784, 500, 10)\n",
    "# model.load_state_dict(torch.load('11_92.05%.pth'))\n",
    "\n",
    "# fusion_model = SimpleMLP(784, 500, 10).to(device)\n",
    "# weighted_sum_parameters(fusion_model, model1, model2,\n",
    "#                         model3, loaded_alpha, loaded_beta)\n",
    "# model = fusion_model\n",
    "\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "\n",
    "# 推理并计算准确度\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs1 = model1(images)\n",
    "        outputs2 = model2(images)\n",
    "        outputs3 = model3(images)\n",
    "\n",
    "        weights = torch.softmax(torch.tensor(\n",
    "            [loaded_alpha, loaded_beta, loaded_gamma], device=device), dim=0)\n",
    "\n",
    "        # 计算加权和的输出\n",
    "        outputs = weights[0] * outputs1 + weights[1] * \\\n",
    "            outputs2 + weights[2] * outputs3\n",
    "        # outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # 推理并计算准确度\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
